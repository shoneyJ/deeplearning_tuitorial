{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming Words with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import *\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PorterStemmer\n",
    "* PorterStemmer uses Suffix Stripping to produce stems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = ['overwhelming', 'overwhelmingly', \n",
    "                'hushed', 'hush',\n",
    "                'functional', 'functionally',\n",
    "                'lying', 'lied',\n",
    "                'fairly', \n",
    "                'destabilize', 'stability',\n",
    "                'friendship', 'friendships', 'friendly', 'friendless', \n",
    "                'connect', 'connections', 'connected',  \n",
    "                'the', 'these', 'those',\n",
    "                'motivational', 'motivate', 'motivating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "\n",
    "ps_stemmed_tokens = []\n",
    "for token in input_tokens:\n",
    "    ps_stemmed_tokens.append(ps.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Porter Stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overwhelming</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overwhelmingly</td>\n",
       "      <td>overwhelmingli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hushed</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functional</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functionally</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lying</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lied</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fairli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>destabilize</td>\n",
       "      <td>destabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stability</td>\n",
       "      <td>stabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>friendship</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendships</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friendli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>these</td>\n",
       "      <td>these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>motivational</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>motivate</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>motivating</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words  Porter Stemmer\n",
       "0     overwhelming       overwhelm\n",
       "1   overwhelmingly  overwhelmingli\n",
       "2           hushed            hush\n",
       "3             hush            hush\n",
       "4       functional        function\n",
       "5     functionally        function\n",
       "6            lying             lie\n",
       "7             lied             lie\n",
       "8           fairly          fairli\n",
       "9      destabilize        destabil\n",
       "10       stability          stabil\n",
       "11      friendship      friendship\n",
       "12     friendships      friendship\n",
       "13        friendly        friendli\n",
       "14      friendless      friendless\n",
       "15         connect         connect\n",
       "16     connections         connect\n",
       "17       connected         connect\n",
       "18             the             the\n",
       "19           these           these\n",
       "20           those           those\n",
       "21    motivational           motiv\n",
       "22        motivate           motiv\n",
       "23      motivating           motiv"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems_df = pd.DataFrame({\n",
    "    'words': input_tokens,\n",
    "    'Porter Stemmer': ps_stemmed_tokens\n",
    "})\n",
    "\n",
    "stems_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LancasterStemmer\n",
    "* The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally.\n",
    "* LancasterStemmer is simple, but heavy stemming due to iterations and over-stemming may occur. \n",
    "* Over-stemming causes the stems to be not linguistic, or they may have no meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = LancasterStemmer()\n",
    "\n",
    "ls_stemmed_tokens = []\n",
    "for token in input_tokens:\n",
    "    ls_stemmed_tokens.append(ls.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Lancaster Stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overwhelming</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overwhelmingly</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hushed</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functional</td>\n",
       "      <td>funct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functionally</td>\n",
       "      <td>funct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lying</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lied</td>\n",
       "      <td>lied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>destabilize</td>\n",
       "      <td>dest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stability</td>\n",
       "      <td>stabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>friendship</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendships</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>these</td>\n",
       "      <td>thes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>those</td>\n",
       "      <td>thos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>motivational</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>motivate</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>motivating</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words Lancaster Stemmer\n",
       "0     overwhelming         overwhelm\n",
       "1   overwhelmingly         overwhelm\n",
       "2           hushed              hush\n",
       "3             hush              hush\n",
       "4       functional             funct\n",
       "5     functionally             funct\n",
       "6            lying             lying\n",
       "7             lied              lied\n",
       "8           fairly              fair\n",
       "9      destabilize              dest\n",
       "10       stability             stabl\n",
       "11      friendship            friend\n",
       "12     friendships            friend\n",
       "13        friendly            friend\n",
       "14      friendless        friendless\n",
       "15         connect           connect\n",
       "16     connections           connect\n",
       "17       connected           connect\n",
       "18             the               the\n",
       "19           these              thes\n",
       "20           those              thos\n",
       "21    motivational               mot\n",
       "22        motivate               mot\n",
       "23      motivating               mot"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems_df = pd.DataFrame({\n",
    "    'words': input_tokens,\n",
    "    'Lancaster Stemmer': ls_stemmed_tokens\n",
    "})\n",
    "\n",
    "stems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Porter Stemmer</th>\n",
       "      <th>Lancaster Stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overwhelming</td>\n",
       "      <td>overwhelm</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overwhelmingly</td>\n",
       "      <td>overwhelmingli</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hushed</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functional</td>\n",
       "      <td>function</td>\n",
       "      <td>funct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functionally</td>\n",
       "      <td>function</td>\n",
       "      <td>funct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lying</td>\n",
       "      <td>lie</td>\n",
       "      <td>lying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lied</td>\n",
       "      <td>lie</td>\n",
       "      <td>lied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fairli</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>destabilize</td>\n",
       "      <td>destabil</td>\n",
       "      <td>dest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stability</td>\n",
       "      <td>stabil</td>\n",
       "      <td>stabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>friendship</td>\n",
       "      <td>friendship</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendships</td>\n",
       "      <td>friendship</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>these</td>\n",
       "      <td>these</td>\n",
       "      <td>thes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "      <td>thos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>motivational</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>motivate</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>motivating</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words  Porter Stemmer Lancaster Stemmer\n",
       "0     overwhelming       overwhelm         overwhelm\n",
       "1   overwhelmingly  overwhelmingli         overwhelm\n",
       "2           hushed            hush              hush\n",
       "3             hush            hush              hush\n",
       "4       functional        function             funct\n",
       "5     functionally        function             funct\n",
       "6            lying             lie             lying\n",
       "7             lied             lie              lied\n",
       "8           fairly          fairli              fair\n",
       "9      destabilize        destabil              dest\n",
       "10       stability          stabil             stabl\n",
       "11      friendship      friendship            friend\n",
       "12     friendships      friendship            friend\n",
       "13        friendly        friendli            friend\n",
       "14      friendless      friendless        friendless\n",
       "15         connect         connect           connect\n",
       "16     connections         connect           connect\n",
       "17       connected         connect           connect\n",
       "18             the             the               the\n",
       "19           these           these              thes\n",
       "20           those           those              thos\n",
       "21    motivational           motiv               mot\n",
       "22        motivate           motiv               mot\n",
       "23      motivating           motiv               mot"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems_df = pd.DataFrame({\n",
    "    'words': input_tokens,\n",
    "    'Porter Stemmer': ps_stemmed_tokens,\n",
    "    'Lancaster Stemmer': ls_stemmed_tokens\n",
    "})\n",
    "\n",
    "stems_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SnowballStemmer\n",
    "* One can generate its own set of rules for any language that is why Python nltk introduced SnowballStemmers that are used to create non-English Stemmers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish')\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss =  SnowballStemmer('english')\n",
    "\n",
    "ss_stemmed_tokens = []\n",
    "for token in input_tokens:\n",
    "    ss_stemmed_tokens.append(ss.stem(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Snowball Stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overwhelming</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overwhelmingly</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hushed</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functional</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functionally</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lying</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lied</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>destabilize</td>\n",
       "      <td>destabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stability</td>\n",
       "      <td>stabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>friendship</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendships</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>these</td>\n",
       "      <td>these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>motivational</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>motivate</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>motivating</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words Snowball Stemmer\n",
       "0     overwhelming        overwhelm\n",
       "1   overwhelmingly        overwhelm\n",
       "2           hushed             hush\n",
       "3             hush             hush\n",
       "4       functional         function\n",
       "5     functionally         function\n",
       "6            lying              lie\n",
       "7             lied              lie\n",
       "8           fairly             fair\n",
       "9      destabilize         destabil\n",
       "10       stability           stabil\n",
       "11      friendship       friendship\n",
       "12     friendships       friendship\n",
       "13        friendly           friend\n",
       "14      friendless       friendless\n",
       "15         connect          connect\n",
       "16     connections          connect\n",
       "17       connected          connect\n",
       "18             the              the\n",
       "19           these            these\n",
       "20           those            those\n",
       "21    motivational            motiv\n",
       "22        motivate            motiv\n",
       "23      motivating            motiv"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems_df = pd.DataFrame({\n",
    "    'words': input_tokens,\n",
    "    'Snowball Stemmer': ss_stemmed_tokens\n",
    "})\n",
    "\n",
    "stems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>Porter Stemmer</th>\n",
       "      <th>Lancaster Stemmer</th>\n",
       "      <th>Snowball Stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>overwhelming</td>\n",
       "      <td>overwhelm</td>\n",
       "      <td>overwhelm</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>overwhelmingly</td>\n",
       "      <td>overwhelmingli</td>\n",
       "      <td>overwhelm</td>\n",
       "      <td>overwhelm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hushed</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "      <td>hush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>functional</td>\n",
       "      <td>function</td>\n",
       "      <td>funct</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>functionally</td>\n",
       "      <td>function</td>\n",
       "      <td>funct</td>\n",
       "      <td>function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lying</td>\n",
       "      <td>lie</td>\n",
       "      <td>lying</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lied</td>\n",
       "      <td>lie</td>\n",
       "      <td>lied</td>\n",
       "      <td>lie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fairly</td>\n",
       "      <td>fairli</td>\n",
       "      <td>fair</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>destabilize</td>\n",
       "      <td>destabil</td>\n",
       "      <td>dest</td>\n",
       "      <td>destabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>stability</td>\n",
       "      <td>stabil</td>\n",
       "      <td>stabl</td>\n",
       "      <td>stabil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>friendship</td>\n",
       "      <td>friendship</td>\n",
       "      <td>friend</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>friendships</td>\n",
       "      <td>friendship</td>\n",
       "      <td>friend</td>\n",
       "      <td>friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>friendly</td>\n",
       "      <td>friendli</td>\n",
       "      <td>friend</td>\n",
       "      <td>friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "      <td>friendless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>connections</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>connected</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "      <td>connect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>these</td>\n",
       "      <td>these</td>\n",
       "      <td>thes</td>\n",
       "      <td>these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "      <td>thos</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>motivational</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>motivate</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>motivating</td>\n",
       "      <td>motiv</td>\n",
       "      <td>mot</td>\n",
       "      <td>motiv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             words  Porter Stemmer Lancaster Stemmer Snowball Stemmer\n",
       "0     overwhelming       overwhelm         overwhelm        overwhelm\n",
       "1   overwhelmingly  overwhelmingli         overwhelm        overwhelm\n",
       "2           hushed            hush              hush             hush\n",
       "3             hush            hush              hush             hush\n",
       "4       functional        function             funct         function\n",
       "5     functionally        function             funct         function\n",
       "6            lying             lie             lying              lie\n",
       "7             lied             lie              lied              lie\n",
       "8           fairly          fairli              fair             fair\n",
       "9      destabilize        destabil              dest         destabil\n",
       "10       stability          stabil             stabl           stabil\n",
       "11      friendship      friendship            friend       friendship\n",
       "12     friendships      friendship            friend       friendship\n",
       "13        friendly        friendli            friend           friend\n",
       "14      friendless      friendless        friendless       friendless\n",
       "15         connect         connect           connect          connect\n",
       "16     connections         connect           connect          connect\n",
       "17       connected         connect           connect          connect\n",
       "18             the             the               the              the\n",
       "19           these           these              thes            these\n",
       "20           those           those              thos            those\n",
       "21    motivational           motiv               mot            motiv\n",
       "22        motivate           motiv               mot            motiv\n",
       "23      motivating           motiv               mot            motiv"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems_df = pd.DataFrame({\n",
    "    'words': input_tokens,\n",
    "    'Porter Stemmer': ps_stemmed_tokens,\n",
    "    'Lancaster Stemmer': ls_stemmed_tokens,\n",
    "    'Snowball Stemmer': ss_stemmed_tokens\n",
    "})\n",
    "\n",
    "stems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix stripping algorithms may differ in results for a variety of reasons. One such reason is whether the algorithm constrains whether the output word must be a real word in the given language. Some approaches do not require the word to actually exist in the language lexicon (the set of all words in the language). Alternatively, some suffix stripping approaches maintain a database (a large list) of all known morphological word roots that exist as real words. These approaches check the list for the existence of the term prior to making a decision. Typically, if the term does not exist, alternate action is taken. This alternate action may involve several other criteria. The non-existence of an output term may serve to cause the algorithm to try alternate suffix stripping rules.\n",
      "\n",
      "It can be the case that two or more suffix stripping rules apply to the same input term, which creates an ambiguity as to which rule to apply. The algorithm may assign (by human hand or stochastically) a priority to one rule or another. Or the algorithm may reject one rule application because it results in a non-existent term whereas the other overlapping rule does not. For example, given the English term friendlies, the algorithm may identify the ies suffix and apply the appropriate rule and achieve the result of friendl. friendl is likely not found in the lexicon, and therefore the rule is rejected.\n",
      "\n",
      "One improvement upon basic suffix stripping is the use of suffix substitution. Similar to a stripping rule, a substitution rule replaces a suffix with an alternate suffix. For example, there could exist a rule that replaces ies with y. How this affects the algorithm varies on the algorithm's design. To illustrate, the algorithm may identify that both the ies suffix stripping rule as well as the suffix substitution rule apply. Since the stripping rule results in a non-existent term in the lexicon, but the substitution rule does not, the substitution rule is applied instead. In this example, friendlies becomes friendly instead of friendl.\n",
      "\n",
      "Diving further into the details, a common technique is to apply rules in a cyclical fashion (recursively, as computer scientists would say). After applying the suffix substitution rule in this example scenario, a second pass is made to identify matching rules on the term friendly, where the ly stripping rule is likely identified and accepted. In summary, friendlies becomes (via substitution) friendly which becomes (via stripping) friend.\n",
      "\n",
      "This example also helps illustrate the difference between a rule-based approach and a brute force approach. In a brute force approach, the algorithm would search for friendlies in the set of hundreds of thousands of inflected word forms and ideally find the corresponding root form friend. In the rule-based approach, the three rules mentioned above would be applied in succession to converge on the same solution. Chances are that the rule-based approach would be slower, as lookup algorithms have a direct access to the solution, while rule-based should try several options, and combinations of them, and then choose which result seems to be the best.\n",
      "\n",
      "There are two error measurements in stemming algorithms, overstemming and understemming. Overstemming is an error where two separate inflected words are stemmed to the same root, but should not have been—a false positive. Understemming is an error where two separate inflected words should be stemmed to the same root, but are not—a false negative. Stemming algorithms attempt to minimize each type of error, although reducing one type can lead to increasing the other.\n",
      "\n",
      "For example, the widely used Porter stemmer stems \"universal\", \"university\", and \"universe\" to \"univers\". This is a case of overstemming: though these three words are etymologically related, their modern meanings are in widely different domains, so treating them as synonyms in a search engine will likely reduce the relevance of the search results.\n",
      "\n",
      "An example of understemming in the Porter stemmer is \"alumnus\" → \"alumnu\", \"alumni\" → \"alumni\", \"alumna\"/\"alumnae\" → \"alumna\". This English word keeps Latin morphology, and so these near-synonyms are not conflated.\n",
      "\n",
      "Stochastic algorithms involve using probability to identify the root form of a word. Stochastic algorithms are trained (they \"learn\") on a table of root form to inflected form relations to develop a probabilistic model. This model is typically expressed in the form of complex linguistic rules, similar in nature to those in suffix stripping or lemmatisation. Stemming is performed by inputting an inflected form to the trained model and having the model produce the root form according to its internal ruleset, which again is similar to suffix stripping and lemmatisation, except that the decisions involved in applying the most appropriate rule, or whether or not to stem the word and just return the same word, or whether to apply two different rules sequentially, are applied on the grounds that the output word will have the highest probability of being correct (which is to say, the smallest probability of being incorrect, which is how it is typically measured).\n",
      "\n",
      "Some lemmatisation algorithms are stochastic in that, given a word which may belong to multiple parts of speech, a probability is assigned to each possible part. This may take into account the surrounding words, called the context, or not. Context-free grammars do not take into account any additional information. In either case, after assigning the probabilities to each possible part of speech, the most likely part of speech is chosen, and from there the appropriate normalization rules are applied to the input word to produce the normalized (root) form.\n"
     ]
    }
   ],
   "source": [
    "with open('./datasets/stemming.txt', 'r') as f:\n",
    "    file_contents = f.read()\n",
    "\n",
    "print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens = word_tokenize(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss =  SnowballStemmer('english', ignore_stopwords=True)\n",
    "\n",
    "ss_stemmed_words = []\n",
    "for word in word_tokens:\n",
    "    ss_stemmed_words.append(ss.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"suffix strip algorithm may differ in result for a varieti of reason . one such reason is whether the algorithm constrain whether the output word must be a real word in the given languag . some approach do not requir the word to actual exist in the languag lexicon ( the set of all word in the languag ) . altern , some suffix strip approach maintain a databas ( a larg list ) of all known morpholog word root that exist as real word . these approach check the list for the exist of the term prior to make a decis . typic , if the term does not exist , altern action is taken . this altern action may involv sever other criteria . the non-exist of an output term may serv to caus the algorithm to tri altern suffix strip rule . it can be the case that two or more suffix strip rule appli to the same input term , which creat an ambigu as to which rule to appli . the algorithm may assign ( by human hand or stochast ) a prioriti to one rule or anoth . or the algorithm may reject one rule applic because it result in a non-exist term wherea the other overlap rule does not . for exampl , given the english term friend , the algorithm may identifi the ie suffix and appli the appropri rule and achiev the result of friendl . friendl is like not found in the lexicon , and therefor the rule is reject . one improv upon basic suffix strip is the use of suffix substitut . similar to a strip rule , a substitut rule replac a suffix with an altern suffix . for exampl , there could exist a rule that replac ie with y . how this affect the algorithm vari on the algorithm 's design . to illustr , the algorithm may identifi that both the ie suffix strip rule as well as the suffix substitut rule appli . sinc the strip rule result in a non-exist term in the lexicon , but the substitut rule does not , the substitut rule is appli instead . in this exampl , friend becom friend instead of friendl . dive further into the detail , a common techniqu is to appli rule in a cyclic fashion ( recurs , as comput scientist would say ) . after appli the suffix substitut rule in this exampl scenario , a second pass is made to identifi match rule on the term friend , where the ly strip rule is like identifi and accept . in summari , friend becom ( via substitut ) friend which becom ( via strip ) friend . this exampl also help illustr the differ between a rule-bas approach and a brute forc approach . in a brute forc approach , the algorithm would search for friend in the set of hundr of thousand of inflect word form and ideal find the correspond root form friend . in the rule-bas approach , the three rule mention above would be appli in success to converg on the same solut . chanc are that the rule-bas approach would be slower , as lookup algorithm have a direct access to the solut , while rule-bas should tri sever option , and combin of them , and then choos which result seem to be the best . there are two error measur in stem algorithm , overstem and understem . overstem is an error where two separ inflect word are stem to the same root , but should not have been—a fals posit . understem is an error where two separ inflect word should be stem to the same root , but are not—a fals negat . stem algorithm attempt to minim each type of error , although reduc one type can lead to increas the other . for exampl , the wide use porter stemmer stem `` univers '' , `` univers '' , and `` univers '' to `` univ '' . this is a case of overstem : though these three word are etymolog relat , their modern mean are in wide differ domain , so treat them as synonym in a search engin will like reduc the relev of the search result . an exampl of understem in the porter stemmer is `` alumnus '' → `` alumnu '' , `` alumni '' → `` alumni '' , `` alumna '' / '' alumna '' → `` alumna '' . this english word keep latin morpholog , and so these near-synonym are not conflat . stochast algorithm involv use probabl to identifi the root form of a word . stochast algorithm are train ( they `` learn '' ) on a tabl of root form to inflect form relat to develop a probabilist model . this model is typic express in the form of complex linguist rule , similar in natur to those in suffix strip or lemmatis . stem is perform by input an inflect form to the train model and having the model produc the root form accord to its intern ruleset , which again is similar to suffix strip and lemmatis , except that the decis involv in appli the most appropri rule , or whether or not to stem the word and just return the same word , or whether to appli two differ rule sequenti , are appli on the ground that the output word will have the highest probabl of being correct ( which is to say , the smallest probabl of being incorrect , which is how it is typic measur ) . some lemmatis algorithm are stochast in that , given a word which may belong to multipl part of speech , a probabl is assign to each possibl part . this may take into account the surround word , call the context , or not . context-fre grammar do not take into account any addit inform . in either case , after assign the probabl to each possibl part of speech , the most like part of speech is chosen , and from there the appropri normal rule are appli to the input word to produc the normal ( root ) form .\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(ss_stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
