{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install seaborn\n",
    "!python -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"elasticsearch>=6.4.0,<7.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "client = Elasticsearch(\"http://172.17.212.35:9200\")\n",
    "resp = client.search(index=\"retromotion-indexer_development_products\",\n",
    "                     body={\"_source\":[\"descriptions\",\"descriptionsSource\",\"nameSource\",\"shortDescriptionSource\",\"categoriesSource\"],\n",
    "                           \"query\": {\"match_all\": {}}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Got %d Hits:\" % resp['hits']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.DataFrame(columns=['name','sdesc','category','catlevel0','catlevel1','catlevel2','catlevel3','catlevel4','catlevel5'])\n",
    "df_de = pd.DataFrame(columns=['name','sdesc','desc','category','categorypath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStr(text):\n",
    "   \n",
    "    # remove numbers\n",
    "    # no_number_string = re.sub(r'\\d+','',lower_string)\n",
    "\n",
    "    # remove all punctuation except words and space\n",
    "    # text = re.sub(r'[^\\w\\s]','', lower_string)\n",
    "\n",
    "    # clean = re.compile('<.*?>')\n",
    "\n",
    "    # text = re.sub(clean,'',text)\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' .join(emoticons).replace('-', ''))\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHtml(html):\n",
    "    dftable = pd.read_html(html)\n",
    "    return dftable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_en=[]\n",
    "name_de=[]\n",
    "\n",
    "sdesc_en=[]\n",
    "sdesc_de=[]\n",
    "\n",
    "desc_en=[]\n",
    "desc_de=[]\n",
    "\n",
    "cat_en=[]\n",
    "cat_de=[]\n",
    "\n",
    "catpath_en=[]\n",
    "catpath_de=[]\n",
    "\n",
    "for hit in resp['hits']['hits']:\n",
    "    list_row =[]\n",
    "    for name in hit['_source']['nameSource']:\n",
    "        if (name[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(name[\"value\"]))\n",
    "        else:\n",
    "            name_de.append(name[\"value\"])\n",
    "    \n",
    "    for sdesc in hit['_source']['shortDescriptionSource']:\n",
    "        if (sdesc[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(sdesc[\"value\"]))\n",
    "        else:\n",
    "            sdesc_de.append(sdesc[\"value\"])\n",
    "\n",
    "    # for desc in hit['_source']['descriptionsSource']:\n",
    "    #     if (desc[\"language\"]==\"en\"):\n",
    "    #         desc_en.append(readHtml(desc[\"value\"]))\n",
    "    #     else:\n",
    "    #         desc_de.append(desc[\"value\"])\n",
    "    \n",
    "    for cats in hit['_source']['categoriesSource']:\n",
    "        if (cats[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(cats[\"label\"]))\n",
    "        else:\n",
    "            desc_de.append(cats[\"label\"])\n",
    "\n",
    "        if (cats[\"language\"]==\"en\"):\n",
    "            categories =cats[\"path\"].split('/')\n",
    "            i =0\n",
    "            catls=[]\n",
    "            for category in categories:\n",
    "\n",
    "                list_row.append(cleanStr(category))\n",
    "                i= i+1\n",
    "            \n",
    "        else:\n",
    "            catpath_de.append(cats[\"path\"])\n",
    "    \n",
    "    # new_row = pd.DataFrame({'name':_name, 'sdesc':_sdesc, 'category':_cat_en }, index=[0])\n",
    "\n",
    "    # pd.concat([new_row,df_eng.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "    for i in range (0,9-len(list_row)):\n",
    "        list_row.append(np.nan)\n",
    "\n",
    "    df_eng.loc[len(df_eng)] = list_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_en = pd.DataFrame({'name':name_en,\n",
    "#                        'sdesc':sdesc_en,\n",
    "#                     #    'desc':desc_en,\n",
    "#                        'category':cat_en,\n",
    "#                        'categorypath':catpath_en})\n",
    "\n",
    "\n",
    "# df_de = pd.DataFrame({'name':name_de,\n",
    "#                        'sdesc':sdesc_de,\n",
    "#                        'desc':desc_de,\n",
    "#                        'category':cat_de,\n",
    "#                        'categorypath':catpath_de})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df_eng.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = df_eng.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eng = pd.get_dummies(df_eng,columns=[\"category\"])\n",
    "# df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "n_gram_vectorizer.fit(df_eng['name'] + df_eng['category'] )\n",
    "transformed_vector_name = n_gram_vectorizer.transform(df_eng['name'])\n",
    "transformed_vector_sdesc = n_gram_vectorizer.transform(df_eng['sdesc'])\n",
    "transformed_vector_category = n_gram_vectorizer.transform(df_eng['category'])\n",
    "\n",
    "# vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_vector_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_vector_name.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_vectorizer.vocabulary_.get('automatic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(transformed_vector_sdesc,\n",
    "                                                    transformed_vector_category,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtrain_ = torch.from_numpy(X_train).float()\n",
    "Xtest_ = torch.from_numpy(x_test).float()\n",
    "Xtrain_.shape\n",
    "Ytrain_ = torch.from_numpy(Y_train).view(1,-1)[0]\n",
    "Ytest_ = torch.from_numpy(y_test).view(1,-1)[0]\n",
    "Ytrain_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = []\n",
    "epochs = 1001\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    Ypred = model(Xtrain_)\n",
    "\n",
    "    loss = loss_fn(Ypred , Ytrain_)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    Ypred_test = model(Xtest_)\n",
    "    loss_test = loss_fn(Ypred_test, Ytest_)\n",
    "    \n",
    "    _,pred = Ypred_test.data.max(1)\n",
    "    \n",
    "    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n",
    "    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print ('epoch - %d (%d%%) train loss - %.2f test loss - %.2f accuracy - %.4f'\\\n",
    "               % (epoch, epoch/150 * 10 , loss.data.item(), loss_test.data.item(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
