{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install seaborn\n",
    "!python -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"elasticsearch>=6.4.0,<7.0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "client = Elasticsearch(\"http://172.17.212.35:9200\")\n",
    "resp = client.search(index=\"retromotion-indexer_development_products\",\n",
    "                     body={\"_source\":[\"descriptions\",\"descriptionsSource\",\"nameSource\",\"shortDescriptionSource\",\"categoriesSource\"],\n",
    "                           \"query\": {\"match_all\": {}}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 22329 Hits:\n"
     ]
    }
   ],
   "source": [
    "print(\"Got %d Hits:\" % resp['hits']['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng = pd.DataFrame(columns=['name','sdesc','category','catlevel0','catlevel1','catlevel2','catlevel3','catlevel4','catlevel5'])\n",
    "df_de = pd.DataFrame(columns=['name','sdesc','desc','category','categorypath'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanStr(text):\n",
    "   \n",
    "    # remove numbers\n",
    "    # no_number_string = re.sub(r'\\d+','',lower_string)\n",
    "\n",
    "    # remove all punctuation except words and space\n",
    "    # text = re.sub(r'[^\\w\\s]','', lower_string)\n",
    "\n",
    "    # clean = re.compile('<.*?>')\n",
    "\n",
    "    # text = re.sub(clean,'',text)\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) + ' ' .join(emoticons).replace('-', ''))\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readHtml(html):\n",
    "    dftable = pd.read_html(html)\n",
    "    return dftable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_en=[]\n",
    "name_de=[]\n",
    "\n",
    "sdesc_en=[]\n",
    "sdesc_de=[]\n",
    "\n",
    "desc_en=[]\n",
    "desc_de=[]\n",
    "\n",
    "cat_en=[]\n",
    "cat_de=[]\n",
    "\n",
    "catpath_en=[]\n",
    "catpath_de=[]\n",
    "\n",
    "for hit in resp['hits']['hits']:\n",
    "    list_row =[]\n",
    "    for name in hit['_source']['nameSource']:\n",
    "        if (name[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(name[\"value\"]))\n",
    "        else:\n",
    "            name_de.append(name[\"value\"])\n",
    "    \n",
    "    for sdesc in hit['_source']['shortDescriptionSource']:\n",
    "        if (sdesc[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(sdesc[\"value\"]))\n",
    "        else:\n",
    "            sdesc_de.append(sdesc[\"value\"])\n",
    "\n",
    "    # for desc in hit['_source']['descriptionsSource']:\n",
    "    #     if (desc[\"language\"]==\"en\"):\n",
    "    #         desc_en.append(readHtml(desc[\"value\"]))\n",
    "    #     else:\n",
    "    #         desc_de.append(desc[\"value\"])\n",
    "    \n",
    "    for cats in hit['_source']['categoriesSource']:\n",
    "        if (cats[\"language\"]==\"en\"):\n",
    "            list_row.append(cleanStr(cats[\"label\"]))\n",
    "        else:\n",
    "            desc_de.append(cats[\"label\"])\n",
    "\n",
    "        if (cats[\"language\"]==\"en\"):\n",
    "            categories =cats[\"path\"].split('/')\n",
    "            i =0\n",
    "            catls=[]\n",
    "            for category in categories:\n",
    "\n",
    "                list_row.append(cleanStr(category))\n",
    "                i= i+1\n",
    "            \n",
    "        else:\n",
    "            catpath_de.append(cats[\"path\"])\n",
    "    \n",
    "    # new_row = pd.DataFrame({'name':_name, 'sdesc':_sdesc, 'category':_cat_en }, index=[0])\n",
    "\n",
    "    # pd.concat([new_row,df_eng.loc[:]]).reset_index(drop=True)\n",
    "\n",
    "    for i in range (0,9-len(list_row)):\n",
    "        list_row.append(np.nan)\n",
    "\n",
    "    df_eng.loc[len(df_eng)] = list_row\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_en = pd.DataFrame({'name':name_en,\n",
    "#                        'sdesc':sdesc_en,\n",
    "#                     #    'desc':desc_en,\n",
    "#                        'category':cat_en,\n",
    "#                        'categorypath':catpath_en})\n",
    "\n",
    "\n",
    "# df_de = pd.DataFrame({'name':name_de,\n",
    "#                        'sdesc':sdesc_de,\n",
    "#                        'desc':desc_de,\n",
    "#                        'category':cat_de,\n",
    "#                        'categorypath':catpath_de})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sdesc</th>\n",
       "      <th>category</th>\n",
       "      <th>catlevel0</th>\n",
       "      <th>catlevel1</th>\n",
       "      <th>catlevel2</th>\n",
       "      <th>catlevel3</th>\n",
       "      <th>catlevel4</th>\n",
       "      <th>catlevel5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denso dtm82363 thermostat coolant</td>\n",
       "      <td>thermostat coolant</td>\n",
       "      <td>thermostat</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>cooling system</td>\n",
       "      <td>thermostat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zf 1043 010 297 automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zf 1060 040 003 automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>automatic transmission</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vaico v10 0131 camshaft</td>\n",
       "      <td>camshaft</td>\n",
       "      <td>camshaft</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>engine</td>\n",
       "      <td>engine timing</td>\n",
       "      <td>camshaft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vaico v26 0302 track control arm</td>\n",
       "      <td>track control arm</td>\n",
       "      <td>track control arm</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>powertrain suspension</td>\n",
       "      <td>wheel suspension</td>\n",
       "      <td>track control arm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name                   sdesc  \\\n",
       "0       denso dtm82363 thermostat coolant      thermostat coolant   \n",
       "1  zf 1043 010 297 automatic transmission  automatic transmission   \n",
       "2  zf 1060 040 003 automatic transmission  automatic transmission   \n",
       "3                 vaico v10 0131 camshaft                camshaft   \n",
       "4        vaico v26 0302 track control arm       track control arm   \n",
       "\n",
       "                 category  catlevel0              catlevel1  \\\n",
       "0              thermostat  sparepart         cooling system   \n",
       "1  automatic transmission  sparepart           transmission   \n",
       "2  automatic transmission  sparepart           transmission   \n",
       "3                camshaft  sparepart                 engine   \n",
       "4       track control arm  sparepart  powertrain suspension   \n",
       "\n",
       "                catlevel2               catlevel3  catlevel4  catlevel5  \n",
       "0              thermostat                     NaN        NaN        NaN  \n",
       "1  automatic transmission  automatic transmission        NaN        NaN  \n",
       "2  automatic transmission  automatic transmission        NaN        NaN  \n",
       "3           engine timing                camshaft        NaN        NaN  \n",
       "4        wheel suspension       track control arm        NaN        NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eng.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = df_eng.groupby('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sdesc</th>\n",
       "      <th>category</th>\n",
       "      <th>catlevel0</th>\n",
       "      <th>catlevel1</th>\n",
       "      <th>catlevel2</th>\n",
       "      <th>catlevel3</th>\n",
       "      <th>catlevel4</th>\n",
       "      <th>catlevel5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>denso dtm82363 thermostat coolant</td>\n",
       "      <td>thermostat coolant</td>\n",
       "      <td>thermostat</td>\n",
       "      <td>sparepart</td>\n",
       "      <td>cooling system</td>\n",
       "      <td>thermostat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                name               sdesc    category  \\\n",
       "0  denso dtm82363 thermostat coolant  thermostat coolant  thermostat   \n",
       "\n",
       "   catlevel0       catlevel1   catlevel2 catlevel3  catlevel4  catlevel5  \n",
       "0  sparepart  cooling system  thermostat       NaN        NaN        NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category.get_group('thermostat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng.iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "n_gram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "n_gram_vectorizer.fit(df_eng['name'] + df_eng['category'] )\n",
    "transformed_vector_name = n_gram_vectorizer.transform(df_eng['name'])\n",
    "transformed_vector_sdesc = n_gram_vectorizer.transform(df_eng['sdesc'])\n",
    "transformed_vector_category = n_gram_vectorizer.transform(df_eng['category'])\n",
    "\n",
    "# vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gram_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_vector_name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_vector_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m transformed_vector_name\u001b[39m.\u001b[39mtoarray()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed_vector_name' is not defined"
     ]
    }
   ],
   "source": [
    "transformed_vector_name.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_gram_vectorizer.vocabulary_.get('automatic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, x_test, Y_train, y_test = train_test_split(transformed_vector_sdesc,\n",
    "                                                    transformed_vector_category,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Xtrain_ = torch.from_numpy(X_train).float()\n",
    "Xtest_ = torch.from_numpy(x_test).float()\n",
    "Xtrain_.shape\n",
    "Ytrain_ = torch.from_numpy(Y_train).view(1,-1)[0]\n",
    "Ytest_ = torch.from_numpy(y_test).view(1,-1)[0]\n",
    "Ytrain_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) \n",
    "        self.fc3 = nn.Linear(hidden_size, output_size) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.sigmoid(self.fc2(x)) \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_data = []\n",
    "epochs = 1001\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    Ypred = model(Xtrain_)\n",
    "\n",
    "    loss = loss_fn(Ypred , Ytrain_)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "        \n",
    "    Ypred_test = model(Xtest_)\n",
    "    loss_test = loss_fn(Ypred_test, Ytest_)\n",
    "    \n",
    "    _,pred = Ypred_test.data.max(1)\n",
    "    \n",
    "    accuracy = pred.eq(Ytest_.data).sum().item() / y_test.values.size\n",
    "    epoch_data.append([epoch, loss.data.item(), loss_test.data.item(), accuracy])\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        print ('epoch - %d (%d%%) train loss - %.2f test loss - %.2f accuracy - %.4f'\\\n",
    "               % (epoch, epoch/150 * 10 , loss.data.item(), loss_test.data.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tf \u001b[39m=\u001b[39m TfidfVectorizer(token_pattern\u001b[39m=\u001b[39m\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(?ui)\u001b[39m\u001b[39m\\b\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39mw*[a-z]+\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw*\u001b[39m\u001b[39m\\b\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m text \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mThis is v000 Sparta!\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> 4\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m  tf\u001b[39m.\u001b[39;49mfit_transform(text)\n\u001b[1;32m      5\u001b[0m feature_names \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mget_feature_names_out() \n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(feature_names)\n",
      "File \u001b[0;32m~/dev/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2133\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[1;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2128\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[1;32m   2129\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[1;32m   2130\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[1;32m   2131\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[1;32m   2132\u001b[0m )\n\u001b[0;32m-> 2133\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[1;32m   2134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[1;32m   2135\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[0;32m~/dev/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1388\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1380\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1381\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1382\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m             )\n\u001b[1;32m   1386\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[1;32m   1390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[1;32m   1391\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/dev/.venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1294\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1292\u001b[0m     vocabulary \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(vocabulary)\n\u001b[1;32m   1293\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vocabulary:\n\u001b[0;32m-> 1294\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1295\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1296\u001b[0m         )\n\u001b[1;32m   1298\u001b[0m \u001b[39mif\u001b[39;00m indptr[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:  \u001b[39m# = 2**31 - 1\u001b[39;00m\n\u001b[1;32m   1299\u001b[0m     \u001b[39mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(token_pattern=u'(?ui)\\b\\w*[a-z]+\\w*\\b')\n",
    "text = [\"This is v000 Sparta!\"]\n",
    "tfidf_matrix =  tf.fit_transform(text)\n",
    "feature_names = tf.get_feature_names_out() \n",
    "print(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
