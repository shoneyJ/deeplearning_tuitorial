notes from tuitorial

auto regresive

feed forward cannot learn from the past
recurrent neuron network can learn from the past
xt -> yt 

unrolling through time


Y = activation (Wx +b)


Stored state - memory
internal state html
each neoron has two weight 


basic cell, LSTM cell , GRU cell 

Gradient decent 

back propogation through time

Long Short Term Memory 





confusion matrix
logsoftmax

https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks