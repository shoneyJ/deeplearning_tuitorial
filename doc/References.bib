@book{Davies.2008cop.2006,
  year      = {2008, cop. 2006},
  title     = {Semantic web technologies: Trends and research in ontology-based systems},
  address   = {Chichester},
  edition   = {Reprinted.},
  publisher = {{J. Wiley {\&} Sons}},
  isbn      = {978-0-470-02596-3},
  editor    = {Davies, J. and Studer, Rudi and Warren, Paul},
  file      = {Davies, Studer et al (Ed) 2008, cop 2006 - Semantic web technologies:Attachments/Davies, Studer et al (Ed) 2008, cop 2006 - Semantic web technologies.pdf:application/pdf}
}


@misc{DuXinya.29042017,
  abstract = {We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rule-based system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer).},
  author   = {{Du Xinya} and Shao, Junru and Cardie, Claire},
  date     = {29/04/2017},
  title    = {Learning to Ask: Neural Question Generation for Reading Comprehension},
  url      = {https://arxiv.org/pdf/1705.00106.pdf},
  urldate  = {28/05/2023},
  file     = {1705.00106:Attachments/1705.00106.pdf:application/pdf}
}

@online{kdnug,
  author       = {Matthew Mayo},
  title        = {{Building a Wikipedia Text Corpus for Natural Language Processing}},
  howpublished = {\url{https://www.kdnuggets.com/2017/11/building-wikipedia-text-corpus-nlp.html}},
  year         = {2017},
  note         = {[Online; accessed 01-May-2023]}
}

@thesis{LisaEhrlinger,
  abstract = {Recently, the term knowledge graph has been used frequently in research and business, usually in close association with Semantic Web technologies, linked data, large-scale data analytics and cloud computing. Its popularity is clearly influenced by the introduction of Google’s Knowledge Graph in 2012, and since then the term has been widely used without a definition. A large variety of interpretations has hampered the evolution of a common understanding of knowledge graphs. Numerous research papers refer to Google’s Knowledge Graph, although no official documentation about the used methods exists. The prerequisite for widespread academic and commercial adoption of a concept or technology is a common understanding, based ideally on a definition that is free from ambiguity. We tackle this issue by discussing and defining the term knowledge graph, considering its history and diversity in interpretations and use. Our goal is to propose a definition of knowledge graphs that serves as basis for discussions on this topic and contributes to a common vision.},
  author   = {Lisa Ehrlinger, Wolfram Wöß},
  title    = {Towards a Definition of Knowledge Graphs},
  keywords = {Knowledge Graphs}
}

% This file was created with Citavi 6.15.2.0

@article{LupeHernandez,
  title   = {Question Generator
             Natural Language Processing},
  author  = {Lupe Hernandez and Sam Randall, Ahmad Nazeri},
  url     = {http://cs230.stanford.edu/projects_fall_2020/reports/55771015.pdf},
  urldate = {29/05/2023},
  file    = {55771015:Attachments/55771015.pdf:application/pdf}
}







% This file was created with Citavi 6.15.2.0

@article{PranavRajpurkar.,
  abstract = {EMNLP2016 2016},
  author   = {{Pranav Rajpurkar} and {Jian Zhang} and {Konstantin Lopyrev} and {Percy Liang}},
  title    = {SQuAD: 100,000+ Questions for Machine Comprehension of Text},
  url      = {https://aclanthology.org/D16-1264.pdf},
  urldate  = {29/05/2023},
  file     = {100,000  Questions for Machine Comprehension of Text:Attachments/100,000  Questions for Machine Comprehension of Text.pdf:application/pdf}
}

@inproceedings{rehurek_lrec,
  title     = {{Software Framework for Topic Modelling with Large Corpora}},
  author    = {Radim {\v R}eh{\r u}{\v r}ek and Petr Sojka},
  booktitle = {{Proceedings of the LREC 2010 Workshop on New
               Challenges for NLP Frameworks}},
  pages     = {45--50},
  year      = 2010,
  month     = May,
  day       = 22,
  publisher = {ELRA},
  address   = {Valletta, Malta},
  language  = {English}
}

@phdthesis{Sukhbaatar.31032015,
  abstract = {We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.},
  author   = {Sukhbaatar, Sainbayar and Szlam, Arthur and Weston, Jason and Fergus, Rob},
  year     = {31/03/2015},
  title    = {End-To-End Memory Networks},
  keywords = {Computer Science - Computation and Language;Computer Science - Neural and Evolutionary Computing},
  file     = {1503.08895:Attachments/1503.08895.pdf:application/pdf}
}

% This file was created with Citavi 6.15.2.0

@article{TorstenZesch,
  title   = {Analyzing and Accessing Wikipedia as a Lexical Semantic Resource},
  author  = {Torsten Zesch, Iryna Gurevych, Max Mühlhäuser
             },
  url     = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=96fcad8bec2bce17d70ca60b042529dd5be513cc},
  urldate = {30/05/2023}
}


% This file was created with Citavi 6.15.2.0

@online{wikiapi,
  year  = {2023},
  title = {Wikipedia API documentation},
  url   = {https://wikipedia-api.readthedocs.io/en/latest/wikipediaapi/api.html}
}



% This file was created with Citavi 6.15.2.0

@online{wkpd,
  author       = {Wikipedia},
  title        = {{Wikipedia special exports}},
  howpublished = {\url{https://en.wikipedia.org/wiki/Special:Export}},
  year         = {2023},
  note         = {[Online; accessed 01-May-2023]}
}





