\chapter{Data collection}


\section {Fetch existing product taxonomy using Elasticsearch}
Elastic search \footnote{https://www.elastic.co/} is a fast and scalable search and analytics engine. It can build a powerful AI and machine learning enabled search experience. In this paper, author fetches labeled dataset of products to serve as the training data for the machine learning model.
Refer section \ref {pyenv} for installation detail of version specific python client of Elastic search. For this project, python client elasticsearch 6.8.2 is installed as the client needs to be compatible with Elastic search version being used. The official Python client provides mapping with Elasticsearch REST APIs.

\begin{lstlisting}[language=Python]
resp=self.es.search("english-name-category",{"_source":["id","name","category"],
'from':_from,
'size' :_size ,
"query": {"match_all": {}}})
\end{lstlisting}

The above code fetches indexed product name and its top hierarchy level category. This record serves as a foundation for multi level category prediction.  

\begin{table}[h]
      \caption{Index: english-name-category statistics}
      \centering
      \label{table:enc}
\begin{tabular}{ll}
      \toprule 

      Samples total&22160 \\
      Dimensionality&2 \\
      Features&name \\
      Target&category \\
      
      \bottomrule
\end{tabular}
\end{table}



\section {Feature selection and dataset sources} \label{sec:feature-selection}

A feature represents a dataset fine-tuned to serve as a training data for machine learning model. The feature selection API from Scikit learn \parencite{sklearn_api} name it as dimensionality reduction. In table \ref{table:enc} the dimensionality is only two. Hence, the obvious choice of feature is "Product name" and target is "Category". Selecting features from higher number of dimensionality is a challenge and a deciding factor to improve the estimators' accuracy scores.\\ 
Various methods for feature selection with Scikit Learn API are:-
\begin{enumerate}
      \item Removing features with low variance
      \item Univariate feature selection
      \item Recursive feature elimination

\end{enumerate}

% The datasets used primarly for extracting feautures will be from the existing product database. In this paper, the datasets used are of an ecommerce business belonging to automotive industry domain. Secondary dataset used is from the TecDoc catalogue by TecAlliance \footnote{https://www.tecalliance.net/}

 Author initially chose to experiment with two-dimensionality, a simple experiment of predicting target which is top level category with feature which is the name of the product. Refer table \ref{table:feature_decription} to view the potential features for an ecommerce domain. 
%   five levels of categories are taken into consideration. The number of category levels differ for each product. Consider an example of category tree with three levels. 

% \begin{quote} 
% \centering 
% sparepart/cooling-system/thermostat
% \end{quote}
% In such case, level 4 and level 5 will be appended with values using data imputation techniques, refer section \ref{dataimput}. 
% \begin{figure}[h]
%       \centering
%       \small{This is text.  It's in a figure environment but it's still text}
%       \caption{\label{fig_text}Some text that can float as a figure}
%   \end{figure}



\begin{table}[h]
      \centering
      \caption{Feature description}
      \label{table:feature_decription}
      \begin{tabular}{ lll }
            \toprule
            
            \textbf{No}& \textbf{Feature} & \textbf{Description}\\
            \midrule
            1&Product name & normalized form of name\\
            2&Category tree & multi level categories\\
            3&Description & Description with html tags\\         
            4&Short description  & product info displayed\\
            5&Supplier  &  supplier of the product\\
            6&Manufacturer  &  manufacturer of the product\\           
            7&Price  &  Price of the product\\
            8&Dimension  & Height, weight of the product\\
            9&(n-1) number of  category levels   &  n is the total category level, one of which will be the target\\
           
            \bottomrule
            \end{tabular}


\end{table}


\section{Summary}

In this chapter, search analytic engine named Elastic search is introduced. The author as a prototype of classification model choose to include only two-dimensionality. One is the feature (product name) and other is the target to be predicted (category.)

Table \ref{table:feature_decription} list the features for determining the product taxonomy. These features are listed based on general knowledge and understanding. However, method for feature selection mentioned by Scikit learn API \parencite{sklearn_api} can be used to determine the features.