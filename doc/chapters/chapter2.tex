\chapter{Data collection}

% One of the major challenge in an ecommerce industry is to categorize the products. The phenominal types of products in the ecommerce web application sold online may require an artificial inteligence generated category tree. The multi level product-categories in the taxonomy tree received and defined from the suppliers or manfucture may not be usable. Since the existing multi level category of those products in ecommerse application may defer. Importing product-category details directly from the various channels may lead to disambugution. The artificial inteligence generated category tree reduces the product ready to deploy time on the production environment. The product ready to deploy time here refers to the check lists of data correctness of the product before listing online.



\section {Fetch existing product taxonomy using Elasticsearch}
Elastic search \footnote{https://www.elastic.co/} is a fast and scalable search and analytics engine. It can build a powerful AI and machine learning enabled search experience. In this paper, author fetches labeled dataset of products to serve as the training data for the machine learning model.
Refer section \ref {pyenv} for installation detail of version specific python client of Elastic search. For this project, python client elasticsearch 6.8.2 is installed as the client needs to be compatible with Elastic search version being used. The official Python client provides mapping with Elasticsearch REST APIs.

\begin{lstlisting}[language=Python]
resp=self.es.search("english-name-category",{"_source":["id","name","category"],
'from':_from,
'size' :_size ,
"query": {"match_all": {}}})
\end{lstlisting}

The above code fetches indexed product name and its top hierarchy level category. This record serves as a foundation for multi level category prediction.  

\begin{table}[h]
      \caption{Index: english-name-category statistics}
      \centering
      \label{table:enc}
\begin{tabular}{ll}
      \toprule 

      Samples total&22160 \\
      Dimensionality&2 \\
      Features&name \\
      Target&category \\
      
      \bottomrule
\end{tabular}
\end{table}

% In table \ref{table:enc}, the total number of products is mentioned.




% Elasticsearch uses \acf{Tf-Idf}. \acs{Tf-Idf} is a technique to generate numeric representation of words. \acs{Tf-Idf} represents product of two terms, \acs{Tf} and \acs{Idf}.

% \begin{math} x_i=tf(w_i) x idf(w_i) \end{math}

\section {Feature selection and dataset sources}

A feature represents a dataset fine-tuned to serve as a training data for machine learning model. The feature selection API from Scikit learn \parencite{sklearn_api} name it as dimensionality reduction. In table \ref{table:enc} the dimensionality is only two. Hence, the obvious choice of feature is "Product name" and target is "Category". Selecting features from higher number of dimensionality is a challenge and a deciding factor to improve the estimators' accuracy scores.\\ 
Various methods for feature selection with Scikit Learn API are:-
\begin{enumerate}
      \item Removing features with low variance
      \item Univariate feature selection
      \item Recursive feature elimination

\end{enumerate}

% The datasets used primarly for extracting feautures will be from the existing product database. In this paper, the datasets used are of an ecommerce business belonging to automotive industry domain. Secondary dataset used is from the TecDoc catalogue by TecAlliance \footnote{https://www.tecalliance.net/}

 Author initially chose to experiment with two-dimensionality, a simple experiment of predicting target which is top level category with feature which is the name of the product. Refer table \ref{table:feature_decription} to view the potential features for an ecommerce domain. 
%   five levels of categories are taken into consideration. The number of category levels differ for each product. Consider an example of category tree with three levels. 

% \begin{quote} 
% \centering 
% sparepart/cooling-system/thermostat
% \end{quote}
% In such case, level 4 and level 5 will be appended with values using data imputation techniques, refer section \ref{dataimput}. 
% \begin{figure}[h]
%       \centering
%       \small{This is text.  It's in a figure environment but it's still text}
%       \caption{\label{fig_text}Some text that can float as a figure}
%   \end{figure}



\begin{table}[h]
      \centering
      \caption{Feature description}
      \label{table:feature_decription}
      \begin{tabular}{ lll }
            \toprule
            
            \textbf{No}& \textbf{Feature} & \textbf{Description}\\
            \midrule
            1&Product name & normalized form of name\\
            2&Category tree & multi level categories\\
            3&Description & Description with html tags\\         
            4&Short description  & product info displayed\\
            5&Supplier  &  supplier of the product\\
            6&Manufacturer  &  manufacturer of the product\\           
            7&Price  &  Price of the product\\
            8&Dimension  & Height, weight of the product\\
            9&(n-1) number of  category levels   &  n is the total category level, one of which will be the target\\
           
            \bottomrule
            \end{tabular}

            % \begin{tabular}{llllll}
            %       \toprule
            %        catlevel0 & catlevel1 & catlevel2 & catlevel3 & catlevel4 & catlevel5 \\
            %       \midrule
            %       sparepart & cooling system & thermostat & NaN & NaN & NaN \\
            
            %       \bottomrule
            % \end{tabular}

\end{table}


% \subsection{Dependency parsing for extracting nouns from features}

% \section {Data imputation techniques - on missing data} \label{dataimput}

% \subsection {Forward and Backward fill}

% \subsection {Impute with mode}