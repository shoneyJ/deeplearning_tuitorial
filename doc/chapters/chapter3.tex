\chapter{Text normalization} \label{text_normalization}

Text normalization is a process of transforming the document into a standard and consistent form of a text. A document is a text from single source. Some examples of document are list of product names from databases, a pdf file, texts retrieved from web scraping. Text normalization enables to perform required operations on the text as the text inputs are consistent across the document. The process of text normalization varies based on the type of text that needs to be normalize. There is no standard method for text normalization task. In this paper, text normalization of product name and category from the database source is performed. 

In table \ref{table:TN}, displays the difference in text before and after normalization. 

\begin{table}[h]
      \caption{Sample of text normalization effect}
      \centering
      \label{table:TN}
\begin{tabular}{lll}
      \toprule 
                  &\textbf{Name} & \textbf{Category} \\ 
      \midrule
      \textbf{Before}& Company V10-4245 Stoßdämpfer & Stoßdämpfer \\
      \textbf{After}&company v104245 stossdaempfer & stossdaempfer \\
      
      \bottomrule
\end{tabular}
\end{table}

\section{Lower case}

Using Pandas - vectorized string method, a text can be lower cased across the document. These methos exclude the missing  / NA values automatically \parencite{mckinney-proc-scipy-2010}.

\begin{lstlisting}[language=Python, caption={Pandas vectorized string method }]
      df_de["name"]= df_de["name"].str.lower()
\end{lstlisting}

\section{Html parsing}

Probability of getting html tags in a document increases if the source of document is from web scraping or also if the document from database source has inline html tags. In such case, fetching normal texts from a html text is required. One of the method would be to use regular expressions to get text in between angel brackets \textless \textgreater text \textless \textgreater. However, this method would require to have the tags to be well formed.
\begin{lstlisting}[language=Python, caption={Regular expression to get text from html}]
      text = re.sub('<[^>]*>', '', text)
\end{lstlisting}



The better option would be to use Beautiful Soup \footnote{https://www.crummy.com/software/BeautifulSoup/bs4/doc/} a Pyhon library for pulling data out of HTLM and XML.
\begin{lstlisting}[language=Python, caption={Beautiful soap API to get text from html}]
      # Remove html tags 
      soup = BeautifulSoup(doc, 'html.parser')
      text =soup.get_text()
\end{lstlisting}

\section{Cleanning text}
A product detail text may contain non-word characters represented in regular expression as \textbackslash W. It may also contain space seperated decimals describing the dimentional values of the product such as weight, height. Regular expressions could be used for removing the non-character words and spaces between the decimal values. 

\begin{lstlisting}[language=Python,,caption={Clean text with Regular expression}]
      text = (re.sub('[-\W]+', ' ', text))
      text = (re.sub('(?<=\d) (?=\d)', '', text))
\end{lstlisting}

\section{Normal form D - Unicode database}

A product name in Deutsch language may contain umlaute characters such as \"A.  Pythons unicodedata \footnote{https://docs.python.org/3/library/unicodedata.html} module provides access to the Unicode Character Database (UCD) which defines the character properties for all Unicode characters. To change \"A to A, the Normal form D (NFD) should be applied which translated each character into its decomposed form. Further the text can be refined with the general category assigned to the character as string. Nonspacing mark characters \footnote{https://www.compart.com/en/unicode/category/Mn} are represented as "Mn". These characters could be removed by referring the character category.
\begin{lstlisting}[language=Python ,caption={NFD normalization}]
      ''.join(
            c for c in unicodedata.normalize('NFD', text)
            if unicodedata.category(c) != 'Mn')
\end{lstlisting}

Another option is to replace the German characters to equivalent English sounding characters. Table \ref{table:deu-eng} lists the common German characters and their equivalent English sounding series of characters. In this way, the reverse translation is easier.
\begin{table}[h]
      \centering
      \caption{German characters to English}
      \label{table:deu-eng}
      \begin{tabular}{ llll }
            \toprule
            \"A& Ö&  Ü&ß \\
            Ae&Oe & Ue&ss\\         
          
            \bottomrule
            \end{tabular}
  \end{table}


  \section{Avoided normalization processes}

  In this project, some commonly practiced normalization process are being avoided. Which once and why are described below.

  \begin{itemize}
      \item Stemming 
      
      Stemming is a process of striping off any affixes. \acl{nlp} tools such as NLTK provide stemmers. The Porter and Lancaster
      stemmers follow their own rules for stripping affixes \parencite{BirdKleinLoper09}. Author required not to deviate from the original vocabulary of features.

      \item Lemmatization
      
      Lemmatization remove the affixes if the word is in the used libraries' dictionary. The vocabulary for corpora and any third party library such as WordNet cannot be synced.   

  \end{itemize}

\section{Summary}

Before extracting the features (refer chapter \ref{sec:feature-extraction}) it is important to normalize and standardize the data set. If the text normalization step is skipped then while creating the numerical representation of the text the data will be inconsistent. For example, same text with proper case (Car) or lower case (car) will have two representation even though the semantic meaning is the same.  

The methods involved in text normalization are lower casing the text, removing the HTML tags, removing irrelevant numerical data within the text such as product dimensionality, and making the text across the document with one Unicode database.
