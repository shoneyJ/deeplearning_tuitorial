\chapter{Building a Knowledge graph} \label{sec:building-kg}

Graph-based knowledge representation has been researched for decades.
A \acf{kg} acquires and integrates information into an ontology and applies a reasoner to derive new knowledge \parencite{LisaEhrlinger}.
The knowledge base is a dataset with formal semantics that can contain different kinds of knowledge, for example, rules, facts, axioms, definitions, statements, and primitives \parencite{Davies.2008cop.2006}.

\begin{figure}[h!]
    \centering
    \includesvg[scale=0.5]{Thesis_kg.svg}
    \caption{\acl{kg} architecture}
    \label{fig:kg}
    \parencite[Chapter 4]{LisaEhrlinger}
\end{figure}

Figure \ref{fig:kg} illustrates the processing of plain text from various sources such as  Wikipedia API, PDF into a graph. This abstract architecture represented by \Citeauthor{LisaEhrlinger} of a \acl{kg} portraits the assumption that a \acl{kg} is more than a \acf{kb}. \acl{kg} is a combination of \acl{kb} and \acf{qe}. 

\Iac{qe} is a set of graph of possible questions that could be formed in reference to \iac{kb}. \acf{qg} for comprehensive reading is a challenging task. There are datasets available for  \acs{qg}, one of it is Stanford Question Answering Dataset v1.0 (SQuAD) consisting of questions posed by crowd workers on a set of Wikipedia articles \parencite{PranavRajpurkar.}. The limitation with such a data set is that these do not contain unanswerable questions. Building a machine learning model when no answer is supported was out of scope of SQuAD objective \parencite{LupeHernandez}.  Study on automatic question generation from an attention-based sequence learning model \parencite{Vaswani.12062017} for  \ac{qg} and investigate the effect of encoding sentence- vs. paragraph-level information \parencite{DuXinya.29042017}, reduces reliance on handcrafted rule based systems.

\clearpage

\section{Fetching text corpus}


One of the first things required for \acf*{nlp} tasks is a creating a text corpus.
In linguistics and \acs{nlp}, corpus refers to a collection of texts. An intriguing application of knowledge graphs within the e-commerce industry involves the creation of a comprehensive information network concerning products. Such a knowledge graph can serve as the basis for chatbots to provide answers to user queries. Converting unstructured text corpus into a directed acyclic graph. Knowledge base serve as a foundation for chatbot applications to traverse through the graph
structure, locate relevant leafs nodes, and formulate human-readable response.


Wikipedia\footnote{https://www.wikipedia.org/} is primarily an encyclopedia with the additional benefit of heavy linking between articles and without the size constraints of paper articles \parencite{TorstenZesch}. 

\section{spaCy - Dependency Parsing} \label{dependencyparsing}

spaCy \parencite{spacy2} features neural models for parsing and entity recognition. These models can be trained for \acf{ner} , tagging and parsing. Its official page on usage\footnote {https://v2.spacy.io/usage/} provides in-depth code example for information extraction.

In figure \ref{fig:dp}, we see a complex sentence's dependency parsing. It has a \acf{nsubj}, connecting \acfp{pobj} with \acfp{adp} and no \acf{dobj}.

\begin{figure}[htp!]
    \centering    
    \includesvg[scale=0.16]{dependency-parser.svg}
    \caption{Navigating the parse tree and subtrees}
    \label{fig:dp}
\end{figure}

The \acs{nsubj} "oil", itself does not give a complete meaning. However, upon combining its dependency noun "Motor", which is "Motor oil"  gives us an understanding of the topic. Traversing from \acs{nsubj} to  \acfp{conj} provides us with three related compound nouns belonging to a similar group.

"Motor oil", "Engine Oil", "Engine Lubricant"

Traversing further right of the dependency tree we can extract the \acsp{pobj}.  An \acf{amod} "internal" is connecting compound noun "combustion engine".

\section{Knowledge graph with Networkx}

The directed graphs created with Networkx \parencite{hagberg2008exploring} is suitable for representing dependency parsing of a sentence mentioned in section \ref{dependencyparsing}. A knowledge base are represented as triples of \acf{SRO}. In which the subject and object are nodes are entities of a graph and relation are directed edges or links between the nodes.

\subsection{What to use as nodes n(x) and edges e(y)?}

In table \ref{table:1}, distingution of triples by  \acs{POS} tags is depicted. 
\begin{table}[h!]
\begin{center}
\begin{tabular}{>{$}l<{$} l}

triples   &   \acf{POS} tags   \\
\hline
n(subject)   &   \acs{nsubj} , \acs{pron}                          \\
n(object)  &   \acs{dobj}    , \acs{pobj}                     \\
e(relation)  &   \acs{adp}, verb
\end{tabular}
\end{center}
\caption{\acs{SRO} and \acs{POS} tags mappings}
\label{table:1}
\end{table}

\section{Summary}


In this chapter, using the dependency parsing of an unstructured sentence, building a knowledge graph is proposed.  The process involves textual information on a product from various sources pass through various methods such as dependency parsing, part of speech tagging, named entity relationship mapping. The processed text is created into a directed graph along with the question engine is called the knowledge graph.  

Further research has to be conducted on generating knowledge graph. As per \parencite{LisaEhrlinger}, there are limitations with knowledge graphs as comprehensive reading is a challenging task.